{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Evaluate trained models on held-out tick data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from models import MarketAgent, make_default_grid\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Tick Data and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"data/ticks\"\n",
    "MODEL_DIR = \"models_ckpts\"\n",
    "NORM_DIR = \"normalization\"\n",
    "\n",
    "# Load tick data\n",
    "tick_files = sorted(glob.glob(os.path.join(DATA_DIR, \"ticks_*.parquet\")))\n",
    "if not tick_files:\n",
    "    raise FileNotFoundError(f\"No tick files found in {DATA_DIR}\")\n",
    "\n",
    "print(f\"Loading {len(tick_files)} tick files...\")\n",
    "dfs = [pd.read_parquet(f) for f in tick_files]\n",
    "df_all = pd.concat(dfs, ignore_index=True).sort_values(\"ts_exchange\")\n",
    "\n",
    "# Select a market with sufficient data\n",
    "df_quotes = df_all[df_all[\"type\"] == \"QUOTE\"].copy()\n",
    "market_counts = df_quotes[\"market_id\"].value_counts()\n",
    "MARKET_ID = market_counts.index[0]\n",
    "\n",
    "print(f\"\\nEvaluating market: {MARKET_ID}\")\n",
    "print(f\"Quote events: {market_counts.iloc[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from structured tick data\n",
    "df = df_quotes[df_quotes[\"market_id\"] == MARKET_ID].copy()\n",
    "\n",
    "# Compute orderbook features\n",
    "df[\"best_bid_prob\"] = df[\"best_yes_price\"] / 100.0\n",
    "df[\"best_ask_prob\"] = (100 - df[\"best_no_price\"]) / 100.0\n",
    "df[\"midpoint\"] = 0.5 * (df[\"best_bid_prob\"] + df[\"best_ask_prob\"])\n",
    "df[\"spread\"] = df[\"best_ask_prob\"] - df[\"best_bid_prob\"]\n",
    "df[\"depth_imb\"] = (df[\"best_yes_size\"] - df[\"best_no_size\"]) / \\\n",
    "                  (df[\"best_yes_size\"] + df[\"best_no_size\"] + 1e-9)\n",
    "\n",
    "# Filter invalid quotes\n",
    "df = df[(df[\"spread\"] > 0) & (df[\"midpoint\"] > 0) & (df[\"midpoint\"] < 1)].reset_index(drop=True)\n",
    "\n",
    "# Build feature matrix (simplified - matches 9 features from compute_micro_features)\n",
    "# For full evaluation, use compute_micro_features with proper TickStore replay\n",
    "X_features = torch.tensor([\n",
    "    df[\"midpoint\"].values,\n",
    "    df[\"spread\"].values,\n",
    "    df[\"depth_imb\"].values,\n",
    "    np.zeros(len(df)),  # trade_imbalance (requires full replay)\n",
    "    np.zeros(len(df)),  # quote_velocity\n",
    "    np.zeros(len(df)),  # q_stale\n",
    "    np.zeros(len(df)),  # t_stale\n",
    "    np.zeros(len(df)),  # time_to_start\n",
    "    np.zeros(len(df)),  # rating_diff\n",
    "]).T.float()\n",
    "\n",
    "# Target: future price (N ticks ahead)\n",
    "HORIZON = 50\n",
    "df[\"target_future\"] = df[\"midpoint\"].shift(-HORIZON)\n",
    "valid_idx = df[\"target_future\"].notna()\n",
    "\n",
    "X_eval = X_features[valid_idx]\n",
    "df_eval = df[valid_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nValid evaluation samples: {len(X_eval):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load agent\n",
    "agent = MarketAgent(MARKET_ID)\n",
    "if not agent.load(base_dir=MODEL_DIR, norm_dir=NORM_DIR):\n",
    "    raise ValueError(f\"Could not load model for {MARKET_ID}. Train it first using train_offline.py!\")\n",
    "\n",
    "print(f\"Loaded model for {MARKET_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running inference...\")\n",
    "\n",
    "agent.model.eval()\n",
    "all_probs = []\n",
    "all_means = []\n",
    "all_vars = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_norm = agent.normalize(X_eval)\n",
    "    loader = DataLoader(TensorDataset(X_norm), batch_size=1024)\n",
    "    \n",
    "    for (xb,) in loader:\n",
    "        logits = agent.model(xb)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        grid_vals = agent.grid.values.to(probs.device)\n",
    "        means = (probs * grid_vals).sum(dim=-1)\n",
    "        vars_ = (probs * (grid_vals ** 2)).sum(dim=-1) - means ** 2\n",
    "        \n",
    "        all_probs.append(probs.cpu())\n",
    "        all_means.append(means.cpu())\n",
    "        all_vars.append(vars_.cpu())\n",
    "\n",
    "probs_tensor = torch.cat(all_probs)\n",
    "df_eval[\"pred_mean\"] = torch.cat(all_means).numpy()\n",
    "df_eval[\"pred_std\"] = torch.sqrt(torch.cat(all_vars)).numpy()\n",
    "\n",
    "print(\"Inference complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar metrics\n",
    "rmse = np.sqrt(np.mean((df_eval[\"pred_mean\"] - df_eval[\"target_future\"])**2))\n",
    "mae = np.mean(np.abs(df_eval[\"pred_mean\"] - df_eval[\"target_future\"]))\n",
    "\n",
    "print(f\"=== Scalar Accuracy ({HORIZON}-tick horizon) ===\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Probabilistic score (Negative Log-Likelihood)\n",
    "grid_vals = agent.grid.values.numpy()\n",
    "target_indices = np.abs(df_eval[\"target_future\"].values[:, None] - grid_vals[None, :]).argmin(axis=1)\n",
    "pred_probs_at_target = probs_tensor[np.arange(len(probs_tensor)), target_indices].numpy()\n",
    "pred_probs_at_target = np.clip(pred_probs_at_target, 1e-6, 1.0)\n",
    "nll = -np.mean(np.log(pred_probs_at_target))\n",
    "\n",
    "print(f\"\\n=== Probabilistic Score ===\")\n",
    "print(f\"NLL: {nll:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction vs Reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a time slice\n",
    "slice_df = df_eval.iloc[1000:1500] if len(df_eval) > 1500 else df_eval.tail(500)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(slice_df[\"ts_exchange\"], slice_df[\"target_future\"], \n",
    "         color=\"black\", label=\"True Future Price\", linewidth=1.5)\n",
    "plt.plot(slice_df[\"ts_exchange\"], slice_df[\"pred_mean\"], \n",
    "         color=\"#FF8C00\", linestyle=\"--\", label=\"Model Prediction\")\n",
    "\n",
    "# Uncertainty bands\n",
    "upper = slice_df[\"pred_mean\"] + 2 * slice_df[\"pred_std\"]\n",
    "lower = slice_df[\"pred_mean\"] - 2 * slice_df[\"pred_std\"]\n",
    "plt.fill_between(slice_df[\"ts_exchange\"], lower, upper, \n",
    "                 color=\"#FF8C00\", alpha=0.2, label=\"95% Confidence\")\n",
    "\n",
    "plt.title(f\"Forecast vs Reality: {MARKET_ID}\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distribution statistics\n",
    "from scipy.stats import entropy\n",
    "\n",
    "df_eval[\"entropy\"] = [entropy(p.numpy()) for p in probs_tensor]\n",
    "df_eval[\"width\"] = df_eval[\"pred_std\"]  # Already computed\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# A. Spread vs Entropy\n",
    "axes[0, 0].scatter(df_eval[\"spread\"], df_eval[\"entropy\"], s=5, alpha=0.3)\n",
    "axes[0, 0].set_xlabel(\"Spread\")\n",
    "axes[0, 0].set_ylabel(\"Distribution Entropy\")\n",
    "axes[0, 0].set_title(\"Uncertainty vs Spread\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# B. Mean Prediction vs True Midpoint\n",
    "axes[0, 1].scatter(df_eval[\"midpoint\"], df_eval[\"pred_mean\"], s=5, alpha=0.3)\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[0, 1].set_xlabel(\"Market Midpoint\")\n",
    "axes[0, 1].set_ylabel(\"Model Prediction\")\n",
    "axes[0, 1].set_title(\"Calibration\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# C. Prediction Error Distribution\n",
    "errors = df_eval[\"pred_mean\"] - df_eval[\"target_future\"]\n",
    "axes[1, 0].hist(errors, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1, 0].axvline(0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "axes[1, 0].set_xlabel(\"Prediction Error\")\n",
    "axes[1, 0].set_ylabel(\"Frequency\")\n",
    "axes[1, 0].set_title(f\"Error Distribution (mean={errors.mean():.4f})\")\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# D. Uncertainty vs Error\n",
    "abs_errors = np.abs(errors)\n",
    "axes[1, 1].scatter(df_eval[\"pred_std\"], abs_errors, s=5, alpha=0.3)\n",
    "axes[1, 1].set_xlabel(\"Model Uncertainty (Ïƒ)\")\n",
    "axes[1, 1].set_ylabel(\"Absolute Error\")\n",
    "axes[1, 1].set_title(\"Uncertainty Calibration\")\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sample Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few example distributions\n",
    "sample_indices = np.linspace(0, len(df_eval)-1, 5, dtype=int)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for idx in sample_indices:\n",
    "    probs = probs_tensor[idx].numpy()\n",
    "    true_val = df_eval.iloc[idx][\"target_future\"]\n",
    "    \n",
    "    plt.plot(grid_vals, probs, \n",
    "             label=f\"t={df_eval.iloc[idx]['ts_exchange']:.0f}, truth={true_val:.2f}\")\n",
    "\n",
    "plt.xlabel(\"Probability Grid\")\n",
    "plt.ylabel(\"Probability Mass\")\n",
    "plt.title(\"Example Predicted Distributions\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
